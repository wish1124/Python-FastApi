import torch
import torch.nn as nn
import numpy as np
import os
import json  # â† ì¶”ê°€!
import warnings

warnings.filterwarnings('ignore')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class QuantileTransformerRegressor(nn.Module):
    """Quantile Regressionì„ ìœ„í•œ Transformer ê¸°ë°˜ ëª¨ë¸"""

    def __init__(self, input_dim, num_quantiles=999, d_model=128, nhead=8,
                 num_layers=3, dim_feedforward=512, dropout=0.1):
        super(QuantileTransformerRegressor, self).__init__()
        self.num_quantiles = num_quantiles

        self.input_embedding = nn.Linear(input_dim, d_model)
        self.pos_encoder = nn.Parameter(torch.randn(1, 1, d_model))

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,
            dropout=dropout, batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.fc_out = nn.Sequential(
            nn.Linear(d_model, dim_feedforward // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward // 2, dim_feedforward // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim_feedforward // 4, num_quantiles)
        )

    def forward(self, x):
        x = self.input_embedding(x)
        x = x.unsqueeze(1) + self.pos_encoder
        x = self.transformer_encoder(x)
        return self.fc_out(x.squeeze(1))


class ProbabilityPredictor:
    """TFT 4-Feature ëª¨ë¸ì„ ì‚¬ìš©í•œ í™•ë¥  ì˜ˆì¸¡ í´ë˜ìŠ¤"""

    def __init__(self, model_path='./results_tft_4feat/best_model.pt'):
        self.model_path = model_path
        self.device = device
        self.quantiles = np.linspace(0.001, 0.999, 999)
        self.feature_names = ['ê¸°ì´ˆê¸ˆì•¡', 'ì¶”ì •ê°€ê²©', 'ì˜ˆê°€ë²”ìœ„', 'ë‚™ì°°í•˜í•œìœ¨']  # â† ìˆœì„œ ë³€ê²½!
        self.model = self._load_model()
        self.scaler = self._load_scaler()  # â† ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¶”ê°€!

    def _load_scaler(self):
        """scalers.json íŒŒì¼ ë¡œë“œ"""
        scaler_path = self.model_path.replace('best_model.pt', 'scalers.json')
        if os.path.exists(scaler_path):
            with open(scaler_path, 'r') as f:
                scaler = json.load(f)
                print(f"âœ“ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: {scaler_path}")
                return scaler
        print(f"âš ï¸  ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ì—†ìŒ: {scaler_path}")
        return None

    def _load_model(self):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        model = QuantileTransformerRegressor(
            input_dim=4, num_quantiles=999, d_model=128, nhead=8,
            num_layers=3, dim_feedforward=512, dropout=0.1
        ).to(self.device)

        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")

        checkpoint = torch.load(self.model_path, map_location=self.device)

        # ë‹¤ì–‘í•œ checkpoint í˜•ì‹ ì²˜ë¦¬
        if isinstance(checkpoint, dict):
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'], strict=False)
            elif 'state_dict' in checkpoint:
                model.load_state_dict(checkpoint['state_dict'], strict=False)
            elif 'model' in checkpoint:
                model.load_state_dict(checkpoint['model'], strict=False)
            else:
                # checkpoint ìì²´ê°€ state_dictì¸ ê²½ìš°
                model.load_state_dict(checkpoint, strict=False)
        else:
            # checkpointê°€ ì§ì ‘ state_dictì¸ ê²½ìš° (ì˜¤ë˜ëœ PyTorch)
            model.load_state_dict(checkpoint, strict=False)

        model.eval()

        print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
        if isinstance(checkpoint, dict) and 'epoch' in checkpoint:
            print(f"  Epoch: {checkpoint['epoch']}, Val Loss: {checkpoint.get('val_loss', 0):.6f}")

        return model

    def _prepare_input(self, input_features):
        """ì…ë ¥ í”¼ì²˜ë¥¼ numpy arrayë¡œ ë³€í™˜ ë° ìŠ¤ì¼€ì¼ë§"""
        if isinstance(input_features, dict):
            # âœ… ìˆœì„œ: ê¸°ì´ˆê¸ˆì•¡, ì¶”ì •ê°€ê²©, ì˜ˆê°€ë²”ìœ„(%), ë‚™ì°°í•˜í•œìœ¨(%)
            X = np.array([[
                input_features['ê¸°ì´ˆê¸ˆì•¡'],
                input_features['ì¶”ì •ê°€ê²©'],
                input_features['ì˜ˆê°€ë²”ìœ„'],  # 0-100 ìŠ¤ì¼€ì¼ (3.5, not 0.035)
                input_features['ë‚™ì°°í•˜í•œìœ¨']  # 0-100 ìŠ¤ì¼€ì¼ (87.74, not 0.8774)
            ]], dtype=np.float32)
        else:
            X = np.array([input_features], dtype=np.float32)
            if X.shape[1] != 4:
                raise ValueError(f"ì…ë ¥ í”¼ì²˜ëŠ” 4ê°œì—¬ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {X.shape[1]}ê°œ")

        # âœ… ìŠ¤ì¼€ì¼ë§ ì ìš©
        if self.scaler is not None:
            x_mean = np.array(self.scaler['x_mean'], dtype=np.float32)
            x_std = np.array(self.scaler['x_std'], dtype=np.float32)
            X = (X - x_mean) / x_std

        return X

    def _predict_quantiles(self, X):
        """999ê°œ quantile ì˜ˆì¸¡ ë° ì—­ë³€í™˜"""
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X).to(self.device)
            pred = self.model(X_tensor).cpu().numpy()[0]  # í‘œì¤€í™”ëœ ë¡œê·¸ ê°’

            # âœ… ì—­ë³€í™˜ (ì—­í‘œì¤€í™” + ì—­ë¡œê·¸)
            if self.scaler is not None:
                y_mean = self.scaler['y_mean']
                y_std = self.scaler['y_std']
                target_log = self.scaler.get('target_log', False)

                # ì—­í‘œì¤€í™”: (pred * std) + mean
                pred = pred * y_std + y_mean

                # ì—­ë¡œê·¸ ë³€í™˜: exp(pred)
                if target_log:
                    pred = np.exp(pred)

            return pred

    def _get_input_features_dict(self, X):
        """ì…ë ¥ í”¼ì²˜ë¥¼ dict í˜•íƒœë¡œ ë°˜í™˜"""
        return {
            'ê¸°ì´ˆê¸ˆì•¡': float(X[0, 0]) if self.scaler is None else float(
                X[0, 0] * self.scaler['x_std'][0] + self.scaler['x_mean'][0]),
            'ì¶”ì •ê°€ê²©': float(X[0, 1]) if self.scaler is None else float(
                X[0, 1] * self.scaler['x_std'][1] + self.scaler['x_mean'][1]),
            'ì˜ˆê°€ë²”ìœ„': float(X[0, 2]) if self.scaler is None else float(
                X[0, 2] * self.scaler['x_std'][2] + self.scaler['x_mean'][2]),
            'ë‚™ì°°í•˜í•œìœ¨': float(X[0, 3]) if self.scaler is None else float(
                X[0, 3] * self.scaler['x_std'][3] + self.scaler['x_mean'][3])
        }

    def predict_probability(self, input_features, lower_bound, upper_bound):
        """íŠ¹ì • êµ¬ê°„ì˜ í™•ë¥  ì˜ˆì¸¡"""
        X = self._prepare_input(input_features)
        pred_quantiles = self._predict_quantiles(X)

        # êµ¬ê°„ ë‚´ í™•ë¥  ê³„ì‚°
        lower_idx = np.searchsorted(pred_quantiles, lower_bound, side='left')
        upper_idx = np.searchsorted(pred_quantiles, upper_bound, side='right')
        probability = (upper_idx - lower_idx) / len(pred_quantiles)

        return {
            'probability': float(probability),
            'probability_percent': float(probability * 100),
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'lower_quantile_index': int(lower_idx),
            'upper_quantile_index': int(upper_idx),
            'median_prediction': float(pred_quantiles[499]),
            'mean_prediction': float(np.mean(pred_quantiles)),
            'input_features': self._get_input_features_dict(X)
        }

    def get_prediction_intervals(self, input_features, confidence_levels=[0.5, 0.8, 0.9, 0.95]):
        """ì—¬ëŸ¬ ì‹ ë¢°êµ¬ê°„ ì˜ˆì¸¡"""
        X = self._prepare_input(input_features)
        pred_quantiles = self._predict_quantiles(X)

        intervals = {}
        for conf in confidence_levels:
            lower_idx = int((1 - conf) / 2 * 999)
            upper_idx = int((1 + conf) / 2 * 999)

            intervals[f'{int(conf * 100)}%'] = {
                'lower': float(pred_quantiles[lower_idx]),
                'upper': float(pred_quantiles[upper_idx]),
                'median': float(pred_quantiles[499]),
                'width': float(pred_quantiles[upper_idx] - pred_quantiles[lower_idx])
            }

        return {
            'intervals': intervals,
            'median_prediction': float(pred_quantiles[499]),
            'mean_prediction': float(np.mean(pred_quantiles)),
            'input_features': self._get_input_features_dict(X)
        }

    def get_highest_probability_ranges(self, input_features, bin_width=0.001, top_k=3):
        """
        Quantile Functionì„ PDFë¡œ ë³€í™˜í•˜ì—¬ í™•ë¥  ë°€ë„ê°€ ë†’ì€ êµ¬ê°„ ì°¾ê¸°

        ìˆ˜í•™ì  ì›ë¦¬:
        - Quantile Function: Q(Ï„) = y, Ï„ âˆˆ [0.001, 0.999]
        - CDF: F(y) = Ï„ (ì—­í•¨ìˆ˜ ê´€ê³„)
        - PDF: f(y) = dF(y)/dy = dÏ„/dy

        ì´ì‚° ê·¼ì‚¬:
        - f(y_i) â‰ˆ Î”Ï„ / Î”Q = (Ï„_{i+1} - Ï„_{i-1}) / (Q_{i+1} - Q_{i-1})
        """
        X = self._prepare_input(input_features)
        pred_quantiles = self._predict_quantiles(X)  # Q(Ï„_i) for i=0..998

        # ğŸ” ë‹¨ì¡°ì„± ê²€ì‚¬
        non_monotonic = np.diff(pred_quantiles) < 0
        if np.any(non_monotonic):
            n_violations = np.sum(non_monotonic)
            print(f"âš ï¸  ê²½ê³ : Quantile Functionì´ {n_violations}ê°œ êµ¬ê°„ì—ì„œ ê°ì†Œí•©ë‹ˆë‹¤!")
            print(f"   ì´ëŠ” ì—­í•¨ìˆ˜ê°€ ì •ì˜ë˜ì§€ ì•ŠëŠ” êµ¬ê°„ì…ë‹ˆë‹¤.")
            violation_indices = np.where(non_monotonic)[0][:5]  # ì²˜ìŒ 5ê°œë§Œ
            for idx in violation_indices:
                print(f"   Ï„={self.quantiles[idx]:.3f}: Q={pred_quantiles[idx]:.4f} â†’ Q={pred_quantiles[idx + 1]:.4f}")

        # 1. PDF ê³„ì‚°: f(y) = Î”Ï„ / Î”Q
        pdf_values = np.zeros(len(pred_quantiles))

        # ì¤‘ì‹¬ì°¨ë¶„ìœ¼ë¡œ PDF ê³„ì‚° (ì–‘ ë ì œì™¸)
        for i in range(1, len(pred_quantiles) - 1):
            delta_tau = self.quantiles[i + 1] - self.quantiles[i - 1]  # 0.002
            delta_Q = pred_quantiles[i + 1] - pred_quantiles[i - 1]

            if abs(delta_Q) > 1e-10:  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                pdf_values[i] = delta_tau / delta_Q
                # ìŒìˆ˜ PDF ë°©ì§€ (ë¹„ë‹¨ì¡° êµ¬ê°„)
                if pdf_values[i] < 0:
                    pdf_values[i] = 0  # ìŒìˆ˜ í™•ë¥ ë°€ë„ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
            else:
                pdf_values[i] = 100.0  # ë§¤ìš° ë†’ì€ ë°€ë„ (í•˜ì§€ë§Œ í˜„ì‹¤ì ì¸ ê°’)

        # ì–‘ ëì  ì²˜ë¦¬ (ì „ì§„/í›„ì§„ ì°¨ë¶„)
        if len(pred_quantiles) > 1:
            # ì²« ì  (ì „ì§„ì°¨ë¶„)
            delta_tau_0 = self.quantiles[1] - self.quantiles[0]
            delta_Q_0 = pred_quantiles[1] - pred_quantiles[0]
            if abs(delta_Q_0) > 1e-10:
                pdf_values[0] = max(0, delta_tau_0 / delta_Q_0)  # ìŒìˆ˜ ë°©ì§€
            else:
                pdf_values[0] = 100.0

            # ë§ˆì§€ë§‰ ì  (í›„ì§„ì°¨ë¶„)
            delta_tau_last = self.quantiles[-1] - self.quantiles[-2]
            delta_Q_last = pred_quantiles[-1] - pred_quantiles[-2]
            if abs(delta_Q_last) > 1e-10:
                pdf_values[-1] = max(0, delta_tau_last / delta_Q_last)  # ìŒìˆ˜ ë°©ì§€
            else:
                pdf_values[-1] = 100.0

        # 2. bin_width ë‹¨ìœ„ë¡œ êµ¬ê°„ì„ ë‚˜ëˆ„ê³  í‰ê·  PDF ê³„ì‚°
        # min/maxë¥¼ bin_width ë‹¨ìœ„ë¡œ ì •ë ¬í•˜ì—¬ ê¹”ë”í•œ ê²½ê³„ ìƒì„±
        min_val = float(pred_quantiles.min())
        max_val = float(pred_quantiles.max())

        # bin_width ë‹¨ìœ„ë¡œ ë‚´ë¦¼/ì˜¬ë¦¼í•˜ì—¬ ì •ë°€ë„ ë§ì¶¤
        min_aligned = np.floor(min_val / bin_width) * bin_width
        max_aligned = np.ceil(max_val / bin_width) * bin_width

        bins = np.arange(min_aligned, max_aligned + bin_width, bin_width)

        bin_info = []
        for i in range(len(bins) - 1):
            lower, upper = bins[i], bins[i + 1]

            # ì´ êµ¬ê°„ì— ì†í•˜ëŠ” quantile ì°¾ê¸°
            in_bin = (pred_quantiles >= lower) & (
                pred_quantiles < upper if i < len(bins) - 2 else pred_quantiles <= upper)
            quantile_indices = np.where(in_bin)[0]

            if len(quantile_indices) == 0:
                continue

            # êµ¬ê°„ ë‚´ í‰ê·  PDF (í™•ë¥ ë°€ë„)
            avg_pdf = float(np.mean(pdf_values[quantile_indices]))

            # êµ¬ê°„ì˜ í™•ë¥  â‰ˆ âˆ« f(y) dy â‰ˆ f(y) Ã— Î”y
            probability = avg_pdf * bin_width

            bin_info.append({
                'range': f'{lower:.0f}ì› ~ {upper:.0f}ì›',
                'lower': float(lower),
                'upper': float(upper),
                'center': float((lower + upper) / 2),
                'pdf': avg_pdf,  # í™•ë¥ ë°€ë„ f(y)
                'probability': float(probability),  # P(y âˆˆ [lower, upper]) - ì •ê·œí™” ì „
                'probability_percent': float(probability * 100)
            })

        # ì „ì²´ í™•ë¥  ì •ê·œí™” (âˆ‘P = 1ì´ ë˜ë„ë¡)
        total_probability = sum(b['probability'] for b in bin_info)
        print(f"[DEBUG] ì •ê·œí™” ì „ total_probability: {total_probability:.4f}")

        if total_probability > 0:
            for b in bin_info:
                old_prob = b['probability']
                b['probability'] = b['probability'] / total_probability
                b['probability_percent'] = b['probability'] * 100

        # PDF ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (í™•ë¥ ë°€ë„ê°€ ë†’ì€ ìˆœ)
        sorted_bins = sorted(bin_info, key=lambda x: x['pdf'], reverse=True)

        return {
            'top_ranges': sorted_bins[:top_k],
            'all_ranges': sorted_bins,
            'total_bins': len(sorted_bins),
            'bin_width': bin_width,
            'prediction_range': {'min': min_val, 'max': max_val, 'range': max_val - min_val},
            'statistics': {
                'median': float(pred_quantiles[499]),
                'mean': float(np.mean(pred_quantiles)),
                'std': float(np.std(pred_quantiles)),
                'q25': float(pred_quantiles[249]),
                'q75': float(pred_quantiles[749])
            },
            'input_features': self._get_input_features_dict(X)
        }

    def get_most_probable_range(self, input_features, bin_width=0.5):
        """ê°€ì¥ í™•ë¥  ë°€ë„ê°€ ë†’ì€ êµ¬ê°„ 1ê°œ ë°˜í™˜"""
        result = self.get_highest_probability_ranges(input_features, bin_width, top_k=1)

        if not result['top_ranges']:
            return None

        most_probable = result['top_ranges'][0]
        return {
            'most_probable_range': most_probable['range'],
            'lower': most_probable['lower'],
            'upper': most_probable['upper'],
            'center': most_probable['center'],
            'probability': most_probable['probability'],
            'probability_percent': most_probable['probability_percent'],
            'statistics': result['statistics'],
            'prediction_range': result['prediction_range'],
            'input_features': result['input_features']
        }

    def get_mode_and_peak_density(self, input_features, bandwidth=0.001):
        """ìµœë¹ˆê°’(mode)ê³¼ peak ë°€ë„ ë¶„ì„"""
        X = self._prepare_input(input_features)
        pred_quantiles = self._predict_quantiles(X)

        # ë°€ë„ ê³„ì‚°
        densities = np.array([
            np.sum(np.abs(pred_quantiles - q_val) <= bandwidth) / 999 / (2 * bandwidth)
            for q_val in pred_quantiles
        ])

        # ìµœëŒ€ ë°€ë„ ì¸ë±ìŠ¤
        peak_idx = np.argmax(densities)
        mode_value = float(pred_quantiles[peak_idx])
        peak_lower, peak_upper = mode_value - bandwidth, mode_value + bandwidth
        peak_count = np.sum((pred_quantiles >= peak_lower) & (pred_quantiles <= peak_upper))

        return {
            'mode': mode_value,
            'mode_quantile': float(self.quantiles[peak_idx]),
            'peak_density': float(densities[peak_idx]),
            'peak_range': {
                'lower': float(peak_lower),
                'upper': float(peak_upper),
                'probability': float(peak_count / 999),
                'probability_percent': float(peak_count / 999 * 100)
            },
            'median': float(pred_quantiles[499]),
            'mean': float(np.mean(pred_quantiles)),
            'std': float(np.std(pred_quantiles)),
            'input_features': self._get_input_features_dict(X)
        }


def main():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("=" * 80)
    print("TFT 4-Feature ëª¨ë¸ - ê°€ì¥ í™•ë¥ ì´ ë†’ì€ êµ¬ê°„ ì˜ˆì¸¡")
    print("=" * 80)

    predictor = ProbabilityPredictor(model_path='./results_transformer/best_model.pt')

    # âœ… ì˜ˆì‹œ ì…ë ¥ê°’ (ë°±ë¶„ìœ¨ ìŠ¤ì¼€ì¼!)
    input_dict = {
        'ê¸°ì´ˆê¸ˆì•¡': 50000000,
        'ì¶”ì •ê°€ê²©': 45000000,
        'ì˜ˆê°€ë²”ìœ„': 3.5,  # â† 3.5% (not 0.035)
        'ë‚™ì°°í•˜í•œìœ¨': 87.74  # â† 87.74% (not 0.8774)
    }

    print(f"\nì…ë ¥ í”¼ì²˜:")
    for key, value in input_dict.items():
        print(f"  {key}: {value}")

    # í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 5ê°œ êµ¬ê°„
    result = predictor.get_highest_probability_ranges(input_dict, bin_width=100000, top_k=5)

    print("\n" + "=" * 80)
    print(f"ëª¨ë¸ ì˜ˆì¸¡ ë²”ìœ„: {result['prediction_range']['min']:.0f}ì› ~ {result['prediction_range']['max']:.0f}ì›")
    print(f"ì¤‘ì•™ê°’: {result['statistics']['median']:.0f}ì›")
    print(f"í‰ê· : {result['statistics']['mean']:.0f}ì›")
    print("=" * 80)

    print("\nâœ¨ í™•ë¥ ì´ ë†’ì€ ìƒìœ„ 5ê°œ êµ¬ê°„:")
    for i, r in enumerate(result['top_ranges'], 1):
        print(f"  {i}ìœ„. {r['range']} (í™•ë¥ : {r['probability_percent']:.2f}%)")


if __name__ == "__main__":
    print(f"Using device: {device}")
    main()