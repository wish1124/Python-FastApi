import math
import uvicorn
import torch
import re
import nest_asyncio
import os
import json
import numpy as np
import uuid
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from pyngrok import ngrok
from fpdf import FPDF  # [ìˆ˜ì •] ì˜¤ë¥˜ê°€ ì¦ì€ md2pdf ëŒ€ì‹  fpdf2 ì‚¬ìš©
from azure.storage.blob import BlobServiceClient, ContentSettings

# --- ëª¨ë“ˆ ì„í¬íŠ¸ ---
try:
    from model_transformer import TransformerRegressor
    from BidAssitanceModel import BidRAGPipeline
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}")
    exit(1)


# ==========================================
# 0. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë° ëª¨ë¸ ë¡œë“œ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==========================================
def parsenumber(value: Any) -> Optional[float]:
    if value is None: return None
    if isinstance(value, (int, float)): return float(value)
    s = str(value).strip()
    s = re.sub(r'[^0-9.\-]', '', s.replace(',', ''))
    try:
        return float(s)
    except:
        return None


def load_scalers_json(path: str):
    if not os.path.exists(path): return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def load_transformer_model(model_path: str):
    if not os.path.exists(model_path):
        return None, {"num_features": 4, "d_model": 64}
    state_dict = torch.load(model_path, map_location='cpu')
    config = {"num_features": 4, "d_model": 64, "num_layers": 2, "dim_feedforward": 256, "nhead": 4}
    print(f"ğŸ›  ì„¤ì •ëœ ëª¨ë¸ êµ¬ì¡°: d_model={config['d_model']}, FFN={config['dim_feedforward']}")
    model = TransformerRegressor(
        num_features=config['num_features'], d_model=config['d_model'],
        num_layers=config['num_layers'], nhead=config['nhead'],
        dim_feedforward=config['dim_feedforward'], dropout=0.1
    )
    try:
        model.load_state_dict(state_dict, strict=True)
        print("ğŸ‰ Transformer ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except RuntimeError as e:
        print(f"âŒ ì‚¬ì´ì¦ˆ ì—ëŸ¬ ë°œìƒ: {e}")
    model.eval()
    return model, config


# ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
MODEL_PATH = "../results_transformer_4feat/transformer_4feat.pt"
SCALER_PATH = "../results_transformer_4feat/scalers.json"
TF_MODEL, TF_CONFIG = load_transformer_model(MODEL_PATH)
SCALER_DATA = load_scalers_json(SCALER_PATH) or {"x_mean": [0] * 4, "x_std": [1] * 4, "y_mean": 0, "y_std": 1}


# ì–´ëŒ‘í„° ë° íŒŒì´í”„ë¼ì¸ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
class TransformerPredictorAdapter:
    def __init__(self, model, scaler_data):
        self.model = model
        self.x_mean = np.array(scaler_data.get('x_mean', [0.0] * 4))
        self.x_std = np.array(scaler_data.get('x_std', [1.0] * 4))
        self.y_mean = float(scaler_data.get('y_mean', 0.0))
        self.y_std = float(scaler_data.get('y_std', 1.0))
        self.target_log = bool(scaler_data.get('target_log', False))

    def predict(self, requirements: Dict[str, Any], retrieved_context: str = "") -> Dict[str, Any]:
        try:
            estimate = parsenumber(requirements.get('estimate_price')) or 1000000.0
            budget = parsenumber(requirements.get('budget')) or estimate
            pr_range = parsenumber(requirements.get('expected_price_range')) or 0.0
            lower_rate = parsenumber(requirements.get('award_lower_rate')) or 0.0
            features = np.array([budget, estimate, pr_range, lower_rate])
            scaled_features = (features - self.x_mean) / self.x_std
            final_pred = estimate
            if self.model:
                input_tensor = torch.tensor(scaled_features, dtype=torch.float32).reshape(1, -1, 1)
                with torch.no_grad():
                    output = self.model(input_tensor)
                    pred_s = output[0].item() if isinstance(output, (tuple, list)) else output.item()
                pred_log = pred_s * self.y_std + self.y_mean
                final_pred = np.expm1(pred_log) if self.target_log else pred_log
            point_estimate = int(round(final_pred))
            return {
                "currency": "KRW", "point_estimate": point_estimate,
                "predicted_min": int(point_estimate * 0.98), "predicted_max": int(point_estimate * 1.02),
                "confidence": "high", "rationale": "Transformer ë¶„ì„ ì™„ë£Œ", "model_type": "Transformer"
            }
        except Exception as e:
            return {"point_estimate": 0, "confidence": "error", "rationale": str(e)}


adapter = TransformerPredictorAdapter(TF_MODEL, SCALER_DATA)
rag_pipeline = BidRAGPipeline(doc_dir="./rag_corpus", index_dir="./rag_index", award_predict_fn=adapter.predict)

# ==========================================
# 3. FastAPI ì„œë²„ ë° PDF ìƒì„± ë¡œì§
# ==========================================
app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])


# --- Azure Blob Storage ì„¤ì • ---
load_dotenv()
AZURE_STORAGE_CONNECTION_STRING = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
AZURE_CONTAINER_NAME = "uploads"

if not AZURE_STORAGE_CONNECTION_STRING:
    raise ValueError("âŒí™˜ê²½ë³€ìˆ˜ 'AZURE_STORAGE_CONNECTION_STRING'ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

def upload_to_azure(file_path, file_name):
    try:
        blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        blob_client = blob_service_client.get_blob_client(container=AZURE_CONTAINER_NAME, blob=file_name)

        # íŒŒì¼ ì—…ë¡œë“œ
        with open(file=file_path, mode="rb") as data:
            blob_client.upload_blob(data, overwrite=True, content_type="application/pdf") # ë‹¤ìš´X ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ ì—´ëŒ
        return blob_client.url
    except Exception as e:
        print(f"Azure ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return e

def generate_pdf(report_text, output_path):
    """fpdf2 OS/2 ì—ëŸ¬ ì™„ë²½ í•´ê²° ë²„ì „ (ë¡œì»¬ í°íŠ¸ ì‚¬ìš©)"""
    try:
        pdf = FPDF()
        pdf.add_page()

        # 1. ì‹œìŠ¤í…œ í°íŠ¸ ëŒ€ì‹  í”„ë¡œì íŠ¸ í´ë” ë‚´ì˜ í°íŠ¸ íŒŒì¼ì„ ì§ì ‘ ì§€ì •
        # NanumGothic-Regular.ttf íŒŒì¼ì„ RAG_server.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ë‘ì„¸ìš”.
        current_dir = os.path.dirname(os.path.abspath(__file__))
        font_path = os.path.join(current_dir, "NanumGothic-Regular.ttf")

        # ë§Œì•½ íŒŒì¼ì´ ì—†ë‹¤ë©´ ì—ëŸ¬ë¥¼ ë¯¸ë¦¬ ì¶œë ¥í•˜ì—¬ ì•ˆë‚´
        if not os.path.exists(font_path):
            raise FileNotFoundError(f"í°íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {font_path} (ë‚˜ëˆ”ê³ ë”•ì„ ë‹¤ìš´ë¡œë“œí•´ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”)")

        # 2. í°íŠ¸ ë“±ë¡ ë° ì„¤ì •
        pdf.add_font("Nanum", "", font_path)
        pdf.set_font("Nanum", size=11)

        # 3. í…ìŠ¤íŠ¸ ì •ì œ (ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°)
        clean_text = report_text.replace("#", "").replace("*", "").replace(">", "").replace("- ", "â€¢ ").strip()

        # 4. ì¶œë ¥ (OS/2 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ latin-1 ì²´í¬ ìš°íšŒ)
        # fpdf2ì˜ multi_cellì€ ìœ ë‹ˆì½”ë“œë¥¼ ê¸°ë³¸ì ìœ¼ë¡œ ì§€ì›í•©ë‹ˆë‹¤.
        pdf.multi_cell(0, 8, txt=clean_text)

        pdf.output(output_path)
    except Exception as e:
        print(f"âŒ [Internal generate_pdf Error] : {e}")
        raise e


@app.post("/analyze")
async def analyze(req: Dict[str, Any]):
    try:
        # 1. ë¶„ì„ ìˆ˜í–‰
        result = rag_pipeline.analyze(req.get("text", ""), thread_id=req.get("thread_id", "default"))
        report_md = result.get("report_markdown", "")

        # 2. PDF ì €ì¥ í´ë” ì¤€ë¹„
        output_dir = "./output"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        pdf_filename = f"report_{uuid.uuid4().hex[:6]}.pdf"
        pdf_path = os.path.join(output_dir, pdf_filename)

        # 3. PDF ìƒì„± ì‹œë„
        try:
            if not report_md:
                raise ValueError("ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")

            generate_pdf(report_md, pdf_path)
            full_pdf_path = os.path.abspath(pdf_path)
            print(f"âœ… PDF ìƒì„± ì„±ê³µ: {full_pdf_path}")

            final_url = upload_to_azure(full_pdf_path, pdf_filename)
            print(f"Azure ì—…ë¡œë“œ URL: {final_url}")
        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì›ì¸ì„ JSON ì‘ë‹µì— í¬í•¨
            print(f"âŒ PDF ìƒì„± ë‹¨ê³„ ìµœì¢… ì‹¤íŒ¨: {e}")
            final_url = f"PDF ìƒì„± ì‹¤íŒ¨: {str(e)}"

        return {
            "extracted_requirements": result.get("requirements", {}),
            "prediction": result.get("prediction_result", {}),
            "report": report_md,
            "pdf_link": final_url
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    nest_asyncio.apply()
    uvicorn.run(app, host="0.0.0.0", port=9999)

ì—¬ê¸° ì½”ë“œëŠ” ëì§€ ê·¸ëŸ¬ë©´?