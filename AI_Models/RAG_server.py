import uvicorn
import torch
import re
import nest_asyncio
import os
import json
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional

# --- ì™¸ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸ (íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • í•„ìš”) ---
try:
    from model_transformer import TransformerRegressor  # ëª¨ë¸ ì •ì˜ íŒŒì¼
    # BidAssitanceModelì´ ê°™ì€ í´ë”ì— ìˆë‹¤ê³  ê°€ì •
    from BidAssitanceModel import BidRAGPipeline, CallableAwardPricePredictor, parsenumber
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("BidAssitanceModel.pyì™€ model_transformer.pyê°€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit(1)

from pyngrok import ngrok

# ==========================================
# 1. Transformer ëª¨ë¸ ë¡œë“œ ë° ì„¤ì • (model_serving.py ë¡œì§)
# ==========================================

def load_transformer_model(model_path: str):
    print(f"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
    state_dict = torch.load(model_path, map_location='cpu')

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ì¶”ë¡ 
    config = {
        "num_features": 4, 
        "d_model": 512, 
        "num_layers": 2, 
        "nhead": 4
    }
    
    # 1. ì…ë ¥ ì°¨ì› ì¶”ë¡ 
    for key, param in state_dict.items():
        if ('input' in key or 'embedding' in key) and 'weight' in key and param.dim() == 2:
            config['num_features'] = param.shape[1]
            config['d_model'] = param.shape[0]
            break
            
    # 2. ë ˆì´ì–´ ê¹Šì´ ì¶”ë¡ 
    max_layer_idx = -1
    for key in state_dict.keys():
        match = re.search(r'layers\.(\d+)\.', key)
        if match:
            max_layer_idx = max(max_layer_idx, int(match.group(1)))
    if max_layer_idx != -1:
        config['num_layers'] = max_layer_idx + 1

    print(f"âœ… ê°ì§€ëœ ëª¨ë¸ ì„¤ì •: {config}")

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = TransformerRegressor(
        num_features=config['num_features'],
        d_model=config['d_model'],
        num_layers=config['num_layers'],
        nhead=4,
        dim_feedforward=config['d_model'] * 4,
        dropout=0.1
    )
    
    model.load_state_dict(state_dict)
    model.eval()
    return model, config

# ì „ì—­ ëª¨ë¸ ë¡œë“œ
MODEL_PATH = "../results_transformer/best_model.pt" # ê²½ë¡œ í™•ì¸ í•„ìš”
TF_MODEL, TF_CONFIG = load_transformer_model(MODEL_PATH)


# ==========================================
# 2. RAG íŒŒì´í”„ë¼ì¸ ì—°ë™ìš© ì–´ëŒ‘í„° ì •ì˜
# ==========================================

class TransformerPredictorAdapter:
    """
    BidRAGPipelineì´ Transformer ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì–´ëŒ‘í„°
    Dict[str, Any] (requirements) -> Tensor -> Dict[str, Any] (prediction result)
    """
    def __init__(self, model, input_dim):
        self.model = model
        self.input_dim = input_dim

    def predict(self, requirements: Dict[str, Any], retrieved_context: str) -> Dict[str, Any]:
        """
        RAG íŒŒì´í”„ë¼ì¸ì—ì„œ í˜¸ì¶œí•˜ëŠ” í‘œì¤€ ì˜ˆì¸¡ í•¨ìˆ˜
        """
        try:
            # 1. íŠ¹ì„± ì¶”ì¶œ (ìˆœì„œ ì¤‘ìš”: budget, estimate, range, rate)
            # BidAssitanceModel.pyì˜ CNN ë¡œì§ê³¼ ë™ì¼í•˜ê²Œ íŒŒì‹±
            budget = parsenumber(requirements.get('budget'))
            estimate = parsenumber(requirements.get('estimate_price'))
            # ì˜ˆê°€ë²”ìœ„, í•˜í•œìœ¨ ì²˜ë¦¬ (ê°„ì†Œí™”ë¨, ì‹¤ì œë¡œëŠ” ì •ê·œ í‘œí˜„ì‹ í•„ìš”í•  ìˆ˜ ìˆìŒ)
            pr_range = parsenumber(requirements.get('expected_price_range'))
            lower_rate = parsenumber(requirements.get('award_lower_rate'))

            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ê¸°ë³¸ê°’ ë˜ëŠ” ì—ëŸ¬)
            features = [
                budget if budget else 0.0,
                estimate if estimate else 0.0,
                pr_range if pr_range else 0.0,
                lower_rate if lower_rate else 0.0
            ]

            # 2. í…ì„œ ë³€í™˜ ë° ì¶”ë¡ 
            input_tensor = torch.tensor([features], dtype=torch.float32)
            
            with torch.no_grad():
                pred_raw = self.model(input_tensor).item()

            # 3. ê²°ê³¼ í¬ë§·íŒ… (RAG íŒŒì´í”„ë¼ì¸ì´ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
            return {
                "currency": "KRW",
                "predicted_min": None, # ë²”ìœ„ ì˜ˆì¸¡ ëª¨ë¸ì´ ì•„ë‹ˆë¯€ë¡œ ë‹¨ì¼ê°’
                "predicted_max": None,
                "point_estimate": round(pred_raw),
                "confidence": "high" if all(f > 0 for f in features) else "low",
                "rationale": f"Transformer Model Inference (Inputs: {features})",
                "model": {"type": "transformer_regressor", "features": features}
            }
            
        except Exception as e:
            return {
                "error": str(e),
                "confidence": "low",
                "rationale": "Inference Failed"
            }

# ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
tf_adapter = TransformerPredictorAdapter(TF_MODEL, TF_CONFIG['num_features'])

# RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
print("ğŸš€ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
rag_pipeline = BidRAGPipeline(
    doc_dir="./rag_corpus",      # ë¬¸ì„œ ê²½ë¡œ
    index_dir="./rag_index",     # FAISS ì¸ë±ìŠ¤ ê²½ë¡œ
    award_predict_fn=tf_adapter.predict  # â˜… Transformer ëª¨ë¸ ì—°ê²°
)


# ==========================================
# 3. FastAPI ì„œë²„ ì„¤ì •
# ==========================================

app = FastAPI(title="Bid Analytics & Prediction API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ìš”ì²­ DTO ---
class PredictBaseRequest(BaseModel):
    features: List[float] = Field(..., description="[budget, estimate, range, rate] ìˆœì„œì˜ 4ê°œ ì‹¤ìˆ˜ ë¦¬ìŠ¤íŠ¸")

class AnalyzeRequest(BaseModel):
    text: str = Field(..., description="ì…ì°° ê³µê³ ë¬¸ ì „ì²´ í…ìŠ¤íŠ¸")
    thread_id: Optional[str] = Field(default="default_thread", description="ëŒ€í™”í˜• ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ìš© ID")

# --- ì—”ë“œí¬ì¸íŠ¸ 1: ê¸°ë³¸ ëª¨ë¸ ì¶”ë¡  (model_serving.py ê¸°ëŠ¥) ---
@app.post("/predictBase")
async def predict_base(req: PredictBaseRequest):
    expected = TF_CONFIG['num_features']
    if len(req.features) != expected:
        raise HTTPException(status_code=400, detail=f"ì…ë ¥ ê°œìˆ˜ ë¶ˆì¼ì¹˜ (ê¸°ëŒ€: {expected}, ì‹¤ì œ: {len(req.features)})")
    
    try:
        input_tensor = torch.tensor([req.features], dtype=torch.float32)
        with torch.no_grad():
            pred = TF_MODEL(input_tensor).item()
        return {"predBid": pred}
    except Exception as e:
        return {"error": str(e), "predBid": 9999}

# --- ì—”ë“œí¬ì¸íŠ¸ 2: RAG ê¸°ë°˜ ì „ì²´ ë¶„ì„ (BidAssitanceModel.py ê¸°ëŠ¥) ---
@app.post("/analyze")
async def analyze_bid(req: AnalyzeRequest):
    """
    ê³µê³ ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ RAG ê²€ìƒ‰ -> ì •ë³´ ì¶”ì¶œ -> Transformer ê°€ê²© ì˜ˆì¸¡ -> ë³´ê³ ì„œ ìƒì„± ìˆ˜í–‰
    """
    try:
        # Pipelineì˜ analyze ë©”ì„œë“œ í˜¸ì¶œ
        results = rag_pipeline.analyze(req.text, thread_id=req.thread_id)
        
        return {
            "requirements": results.get("requirements"), # ì¶”ì¶œëœ ì •ë³´
            "report_markdown": results.get("report_markdown"), # LLM ë¶„ì„ ë³´ê³ ì„œ
            "prediction": results.get("prediction_result") # Transformer ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨ë¨
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    return {"status": "online", "model": "TransformerRegressor", "pipeline": "BidRAG"}

# ==========================================
# 4. ì„œë²„ ì‹¤í–‰ (ngrok í¬í•¨)
# ==========================================

if __name__ == "__main__":
    # ngrok ì„¤ì •
    AUTH_TOKEN = "38H6WIHF5Hn1xV68lPnXu15Tutc_4PDGKRtxpJhbJuVdcUCEp" # ê¸°ì¡´ í† í° ìœ ì§€
    ngrok.set_auth_token(AUTH_TOKEN)
    
    port = 9999
    public_url = ngrok.connect(port).public_url
    print(f"ğŸŒ ê³µìš© URL: {public_url}")

    nest_asyncio.apply()
    uvicorn.run(app, host="0.0.0.0", port=port)
